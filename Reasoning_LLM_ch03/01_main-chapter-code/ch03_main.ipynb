{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9bba24bf-3592-47d2-bfb1-5177324a418e",
      "metadata": {
        "id": "9bba24bf-3592-47d2-bfb1-5177324a418e"
      },
      "source": [
        "<table style=\"width:100%\">\n",
        "<tr>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<font size=\"2\">\n",
        "Supplementary code for the <a href=\"https://mng.bz/lZ5B\">Build a Reasoning Model (From Scratch)</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
        "<br>Code repository: <a href=\"https://github.com/rasbt/reasoning-from-scratch\">https://github.com/rasbt/reasoning-from-scratch</a>\n",
        "</font>\n",
        "</td>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<a href=\"https://mng.bz/lZ5B\"><img src=\"https://sebastianraschka.com/images/reasoning-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
        "</td>\n",
        "</tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90fa0a7f-b86b-4a92-9957-18f8a4398290",
      "metadata": {
        "id": "90fa0a7f-b86b-4a92-9957-18f8a4398290"
      },
      "source": [
        "# Chapter 3: Evaluating Reasoning Models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the repository and install dependencies\n",
        "!git clone https://github.com/rasbt/reasoning-from-scratch.git\n",
        "%cd reasoning-from-scratch/ch03/01_main-chapter-code/\n",
        "\n",
        "# Install required packages\n",
        "!pip install torch torchvision tiktoken datasets tqdm"
      ],
      "metadata": {
        "id": "LlLrxixZSlRb",
        "outputId": "b7ad0283-f397-43ff-b517-9650211457de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LlLrxixZSlRb",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'reasoning-from-scratch' already exists and is not an empty directory.\n",
            "/content/reasoning-from-scratch/ch03/01_main-chapter-code\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.35.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the repo if not already done\n",
        "import os\n",
        "if not os.path.exists('reasoning-from-scratch'):\n",
        "    !git clone https://github.com/rasbt/reasoning-from-scratch.git\n",
        "\n",
        "# Install the project as a package\n",
        "%cd reasoning-from-scratch\n",
        "!pip install -e .\n",
        "\n",
        "# Install other dependencies\n",
        "!pip install torch tiktoken datasets tqdm"
      ],
      "metadata": {
        "id": "sq32yCm1UKcg",
        "outputId": "73d670e4-39e0-4aa4-b0b5-ddaee4cd079f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "sq32yCm1UKcg",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/reasoning-from-scratch/ch03/01_main-chapter-code/reasoning-from-scratch\n",
            "Obtaining file:///content/reasoning-from-scratch/ch03/01_main-chapter-code/reasoning-from-scratch\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jupyterlab>=4.4.7 in /usr/local/lib/python3.12/dist-packages (from reasoning_from_scratch==0.1.7) (4.4.9)\n",
            "Requirement already satisfied: torch>=2.7.1 in /usr/local/lib/python3.12/dist-packages (from reasoning_from_scratch==0.1.7) (2.8.0+cu126)\n",
            "Requirement already satisfied: tokenizers>=0.21.2 in /usr/local/lib/python3.12/dist-packages (from reasoning_from_scratch==0.1.7) (0.22.1)\n",
            "Requirement already satisfied: nbformat>=5.10.4 in /usr/local/lib/python3.12/dist-packages (from reasoning_from_scratch==0.1.7) (5.10.4)\n",
            "Requirement already satisfied: sympy>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from reasoning_from_scratch==0.1.7) (1.14.0)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (2.0.5)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (0.28.1)\n",
            "Requirement already satisfied: ipykernel!=6.30.0,>=6.5.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (6.17.1)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (5.8.1)\n",
            "Requirement already satisfied: jupyter-lsp>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (2.3.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (2.14.0)\n",
            "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (2.27.3)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (0.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (25.0)\n",
            "Requirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (75.2.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (6.4.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (5.7.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.10.4->reasoning_from_scratch==0.1.7) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.10.4->reasoning_from_scratch==0.1.7) (4.25.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.14.0->reasoning_from_scratch==0.1.7) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.21.2->reasoning_from_scratch==0.1.7) (0.35.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->reasoning_from_scratch==0.1.7) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->reasoning_from_scratch==0.1.7) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->reasoning_from_scratch==0.1.7) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->reasoning_from_scratch==0.1.7) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->reasoning_from_scratch==0.1.7) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->reasoning_from_scratch==0.1.7) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->reasoning_from_scratch==0.1.7) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->reasoning_from_scratch==0.1.7) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->reasoning_from_scratch==0.1.7) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->reasoning_from_scratch==0.1.7) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->reasoning_from_scratch==0.1.7) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->reasoning_from_scratch==0.1.7) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->reasoning_from_scratch==0.1.7) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->reasoning_from_scratch==0.1.7) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->reasoning_from_scratch==0.1.7) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->reasoning_from_scratch==0.1.7) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->reasoning_from_scratch==0.1.7) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->reasoning_from_scratch==0.1.7) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.7.1->reasoning_from_scratch==0.1.7) (3.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (0.16.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.21.2->reasoning_from_scratch==0.1.7) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.21.2->reasoning_from_scratch==0.1.7) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.21.2->reasoning_from_scratch==0.1.7) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.21.2->reasoning_from_scratch==0.1.7) (1.1.10)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (1.8.15)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (26.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=3.0.3->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.10.4->reasoning_from_scratch==0.1.7) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.10.4->reasoning_from_scratch==0.1.7) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.10.4->reasoning_from_scratch==0.1.7) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat>=5.10.4->reasoning_from_scratch==0.1.7) (0.27.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (4.5.0)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (25.1.0)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (0.5.3)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (7.16.6)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (7.7.0)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (0.23.1)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (1.9.0)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (2.17.0)\n",
            "Requirement already satisfied: json5>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (0.12.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.25.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (1.3.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (25.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (4.9.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (2.9.0.post0)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (4.0.0)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (0.1.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (1.5.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.16.4->tokenizers>=0.21.2->reasoning_from_scratch==0.1.7) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.16.4->tokenizers>=0.21.2->reasoning_from_scratch==0.1.7) (2.5.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.12/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (1.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (0.8.5)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (24.11.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (0.2.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (1.17.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (2.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (2.8)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (2.23)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (1.3.0)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.12/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.4.7->reasoning_from_scratch==0.1.7) (2.9.0.20251008)\n",
            "Building wheels for collected packages: reasoning_from_scratch\n",
            "  Building editable for reasoning_from_scratch (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for reasoning_from_scratch: filename=reasoning_from_scratch-0.1.7-0.editable-py3-none-any.whl size=14204 sha256=91d9c55ca7ad0cf4c56c0b9ef63c9d0dc4e810288b572d7aa441a5c6e3d1bf38\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_q0ndbqe/wheels/7d/52/8f/a6faaf24cd22b7dc4e4459c340e9b82bf85b0bccb8ffab2205\n",
            "Successfully built reasoning_from_scratch\n",
            "Installing collected packages: reasoning_from_scratch\n",
            "  Attempting uninstall: reasoning_from_scratch\n",
            "    Found existing installation: reasoning_from_scratch 0.1.7\n",
            "    Uninstalling reasoning_from_scratch-0.1.7:\n",
            "      Successfully uninstalled reasoning_from_scratch-0.1.7\n",
            "Successfully installed reasoning_from_scratch-0.1.7\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.35.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import tiktoken\n",
        "import importlib.metadata\n",
        "\n",
        "# Only check real packages, skip reasoning_from_scratch\n",
        "real_packages = ['torch', 'tiktoken', 'tqdm']\n",
        "\n",
        "for lib in real_packages:\n",
        "    try:\n",
        "        print(f\"{lib} version: {importlib.metadata.version(lib)}\")\n",
        "    except:\n",
        "        print(f\"{lib}: not installed\")"
      ],
      "metadata": {
        "id": "ZQIDU3v7TW4w",
        "outputId": "27b63a53-09b4-4cca-901c-79fcaf1ee397",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZQIDU3v7TW4w",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.8.0+cu126\n",
            "tiktoken version: 0.12.0\n",
            "tqdm version: 4.67.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MofuwHnZVArs"
      },
      "id": "MofuwHnZVArs"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Y4-fymVjU_ez"
      },
      "id": "Y4-fymVjU_ez"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d2c83184-31d0-4bcd-a7ea-67ee366736ea",
      "metadata": {
        "id": "d2c83184-31d0-4bcd-a7ea-67ee366736ea",
        "outputId": "10e7618f-202d-4406-8b71-de2c14586a2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reasoning_from_scratch version: 0.1.7\n",
            "torch version: 2.8.0+cu126\n",
            "sympy version: 1.14.0\n",
            "tokenizers version: 0.22.1\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "used_libraries = [\n",
        "    \"reasoning_from_scratch\",\n",
        "    \"torch\",\n",
        "    \"sympy\",\n",
        "    \"tokenizers\"  # Used by reasoning_from_scratch\n",
        "]\n",
        "\n",
        "for lib in used_libraries:\n",
        "    print(f\"{lib} version: {version(lib)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb4aa7b8-25bc-4a1a-978c-19cfdc059d97",
      "metadata": {
        "id": "eb4aa7b8-25bc-4a1a-978c-19cfdc059d97"
      },
      "source": [
        "<br>\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/reasoning-from-scratch-images/ch03/CH03_F01_raschka.webp?1\" width=\"500px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65ecfa9d-b502-4ec5-b80c-e67142273718",
      "metadata": {
        "id": "65ecfa9d-b502-4ec5-b80c-e67142273718"
      },
      "source": [
        "&nbsp;\n",
        "## 3.1 Building a math verifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17412c95-a620-4b3f-978f-39525dba7fd9",
      "metadata": {
        "id": "17412c95-a620-4b3f-978f-39525dba7fd9"
      },
      "source": [
        "- No code in this section"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f815d4c6-71ae-4d21-80a3-5451822d6bd3",
      "metadata": {
        "id": "f815d4c6-71ae-4d21-80a3-5451822d6bd3"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/reasoning-from-scratch-images/ch03/CH03_F02_raschka.webp?1\" width=\"500px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a65814d-2497-4270-aa02-14efa8a05658",
      "metadata": {
        "id": "0a65814d-2497-4270-aa02-14efa8a05658"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/reasoning-from-scratch-images/ch03/CH03_F03_raschka.webp?1\" width=\"500px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57a963b9-5ae8-4471-8d80-c2295e034465",
      "metadata": {
        "id": "57a963b9-5ae8-4471-8d80-c2295e034465"
      },
      "source": [
        "&nbsp;\n",
        "## 3.2 Loading a pre-trained model to generate text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "387f8c7e-6508-494b-a233-1edee5c2649f",
      "metadata": {
        "id": "387f8c7e-6508-494b-a233-1edee5c2649f"
      },
      "source": [
        "- In this section, we load the model (recap of chapter 2) that we want to evaluate\n",
        "- Note that we use the base model here; once you have completed this chapter, you can rerun the notebook after changing `WHICH_MODEL = \"base\"` to `WHICH_MODEL = \"reasoning\"` to evaluate an already trained reasoning model"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HhRCqUkuU26i"
      },
      "id": "HhRCqUkuU26i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "242ef7f6-c9ac-49b0-bd57-a09d325f4dbc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "242ef7f6-c9ac-49b0-bd57-a09d325f4dbc",
        "outputId": "0742514f-1e2f-418b-d914-e639c6855c3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CPU\n",
            "qwen3-0.6B-base.pth:  56% (807 MiB / 1433 MiB)"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2761999705.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mWHICH_MODEL\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"base\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     download_qwen3_small(\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"base\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"qwen3\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     )\n",
            "\u001b[0;32m/content/reasoning-from-scratch/ch03/01_main-chapter-code/reasoning-from-scratch/reasoning_from_scratch/qwen3.py\u001b[0m in \u001b[0;36mdownload_qwen3_small\u001b[0;34m(kind, tokenizer_only, out_dir)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0mprimary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhf_fmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mbackup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{backup_root}/{fname}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackup_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/reasoning-from-scratch/ch03/01_main-chapter-code/reasoning-from-scratch/reasoning_from_scratch/utils.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(url, out_dir, backup_url)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# Try main URL first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtry_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/reasoning-from-scratch/ch03/01_main-chapter-code/reasoning-from-scratch/reasoning_from_scratch/utils.py\u001b[0m in \u001b[0;36mtry_download\u001b[0;34m(u)\u001b[0m\n\u001b[1;32m     33\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                         \u001b[0mdownloaded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0msize_remote\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "from reasoning_from_scratch.ch02 import (\n",
        "    get_device\n",
        ")\n",
        "from reasoning_from_scratch.qwen3 import (\n",
        "    download_qwen3_small,\n",
        "    Qwen3Tokenizer,\n",
        "    Qwen3Model,\n",
        "    QWEN_CONFIG_06_B\n",
        ")\n",
        "\n",
        "device = get_device()\n",
        "\n",
        "# Lower precision from \"highest\" (default)\n",
        "# which enables Tensor Cores if applicable\n",
        "torch.set_float32_matmul_precision(\"high\")\n",
        "\n",
        "# If you have compatibility issues, try to\n",
        "# uncomment the line below and rerun the notebook\n",
        "# device = \"cpu\"\n",
        "\n",
        "WHICH_MODEL = \"base\"\n",
        "\n",
        "if WHICH_MODEL == \"base\":\n",
        "\n",
        "    download_qwen3_small(\n",
        "        kind=\"base\", tokenizer_only=False, out_dir=\"qwen3\"\n",
        "    )\n",
        "\n",
        "    tokenizer_path = Path(\"qwen3\") / \"tokenizer-base.json\"\n",
        "    model_path = Path(\"qwen3\") / \"qwen3-0.6B-base.pth\"\n",
        "    tokenizer = Qwen3Tokenizer(tokenizer_file_path=tokenizer_path)\n",
        "\n",
        "elif WHICH_MODEL == \"reasoning\":\n",
        "\n",
        "    download_qwen3_small(\n",
        "        kind=\"reasoning\", tokenizer_only=False, out_dir=\"qwen3\"\n",
        "    )\n",
        "\n",
        "    tokenizer_path = Path(\"qwen3\") / \"tokenizer-reasoning.json\"\n",
        "    model_path = Path(\"qwen3\") / \"qwen3-0.6B-reasoning.pth\"\n",
        "    tokenizer = Qwen3Tokenizer(\n",
        "        tokenizer_file_path=tokenizer_path,\n",
        "        apply_chat_template=True,\n",
        "        add_generation_prompt=True,\n",
        "        add_thinking=True,\n",
        "    )\n",
        "\n",
        "else:\n",
        "    raise ValueError(f\"Invalid choice: WHICH_MODEL={WHICH_MODEL}\")\n",
        "\n",
        "\n",
        "model = Qwen3Model(QWEN_CONFIG_06_B)\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "USE_COMPILE = False  # Set to true to enable compilation\n",
        "if USE_COMPILE:\n",
        "  torch._dynamo.config.allow_unspec_int_on_nn_module = True\n",
        "  model = torch.compile(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5ec34ff-674e-47ba-bb4b-1a981567760d",
      "metadata": {
        "id": "e5ec34ff-674e-47ba-bb4b-1a981567760d"
      },
      "source": [
        "- Instead of the `generate_text_basic_stream` function introduced in chapter 2, we use the slightly modified `generate_text_basic_stream_cache` version (from [exercise 2.2](../../ch02/01_main-chapter-code/ch02_exercise-solutions.ipynb) as it prints the tokens as soon as they are generated, which can be useful for debugging purposes (so it doesn't appear the LLM is stuck when generating the response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0e7082a7-3013-4489-9d87-a2e1790f1009",
      "metadata": {
        "id": "0e7082a7-3013-4489-9d87-a2e1790f1009",
        "outputId": "655befd1-4202-41b3-c8e7-67761ceff33a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3214969636.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Similar to chapter 2 exercise solution:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m input_token_ids_tensor = torch.tensor(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "from reasoning_from_scratch.ch02_ex import (\n",
        "    generate_text_basic_stream_cache\n",
        ")\n",
        "\n",
        "prompt = (\n",
        "    r\"If $a+b=3$ and $ab=\\tfrac{13}{6}$, \"\n",
        "    r\"what is the value of $a^2+b^2$?\"\n",
        ")\n",
        "\n",
        "# Similar to chapter 2 exercise solution:\n",
        "input_token_ids_tensor = torch.tensor(\n",
        "    tokenizer.encode(prompt),\n",
        "    device=device\n",
        "    ).unsqueeze(0)\n",
        "\n",
        "all_token_ids = []\n",
        "for token in generate_text_basic_stream_cache(\n",
        "    model=model,\n",
        "    token_ids=input_token_ids_tensor,\n",
        "    max_new_tokens=2048,\n",
        "    eos_token_id=tokenizer.eos_token_id\n",
        "):\n",
        "    token_id = token.squeeze(0)\n",
        "    decoded_id = tokenizer.decode(token_id.tolist())\n",
        "    print(\n",
        "        decoded_id,\n",
        "        end=\"\",\n",
        "        flush=True\n",
        "    )\n",
        "    all_token_ids.append(token_id)\n",
        "\n",
        "all_tokens = tokenizer.decode(all_token_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7300363-1109-4bed-9aeb-24d3d4c6c745",
      "metadata": {
        "id": "d7300363-1109-4bed-9aeb-24d3d4c6c745"
      },
      "source": [
        "- If you are unfamiliar with LaTeX syntax, the response above can be very hard to read\n",
        "- You can use the `Latex` class to render the LaTeX syntax to improve readability, as shown below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fbbd72a-5dce-4d99-bcc3-b83645affeab",
      "metadata": {
        "id": "3fbbd72a-5dce-4d99-bcc3-b83645affeab"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Latex, display\n",
        "\n",
        "display(Latex(all_tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e0ab369-29b6-4145-9ae6-4341d7db3cbf",
      "metadata": {
        "id": "7e0ab369-29b6-4145-9ae6-4341d7db3cbf"
      },
      "source": [
        "- If you only want to render specific math expressions, you can also use the `Math` class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a348e6e5-0f74-4061-9c3c-1b06d8171b89",
      "metadata": {
        "id": "a348e6e5-0f74-4061-9c3c-1b06d8171b89"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Math\n",
        "\n",
        "display(Math(r\"\\dfrac{14}{3}\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f443a99-4eb9-40cd-a25e-c1f4f054aba0",
      "metadata": {
        "id": "1f443a99-4eb9-40cd-a25e-c1f4f054aba0"
      },
      "source": [
        "&nbsp;\n",
        "## 3.3 Implementing a wrapper for easier text generation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "566759b7-c950-4fa5-abd6-e967e91e497c",
      "metadata": {
        "id": "566759b7-c950-4fa5-abd6-e967e91e497c"
      },
      "source": [
        "- Above, we loaded the pre-trained LLM and set up the text generation functionality (as illustrated in the figure below), which are the first two steps of the evaluation process covered in the remainder of this chapter"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69e31a7b-c37a-40a6-95cc-fffe5a17a33e",
      "metadata": {
        "id": "69e31a7b-c37a-40a6-95cc-fffe5a17a33e"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/reasoning-from-scratch-images/ch03/CH03_F05_raschka.webp?1\" width=\"500px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2f4ac6b-31b3-49af-9b80-bb479c124dbd",
      "metadata": {
        "id": "a2f4ac6b-31b3-49af-9b80-bb479c124dbd"
      },
      "source": [
        "- For additional convenience, we create a wrapper function for the text generation function so that we only have to pass in the model, tokenizer, and prompt, along with some additional settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "628423fc-87d3-4ae6-b453-399106f4173e",
      "metadata": {
        "id": "628423fc-87d3-4ae6-b453-399106f4173e"
      },
      "outputs": [],
      "source": [
        "def generate_text_stream_concat(\n",
        "    model, tokenizer, prompt, device, max_new_tokens,\n",
        "    verbose=False,\n",
        "):\n",
        "    input_ids = torch.tensor(\n",
        "        tokenizer.encode(prompt), device=device\n",
        "        ).unsqueeze(0)\n",
        "\n",
        "    generated_ids = []\n",
        "    for token in generate_text_basic_stream_cache(\n",
        "        model=model,\n",
        "        token_ids=input_ids,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "    ):\n",
        "        next_token_id = token.squeeze(0)\n",
        "        generated_ids.append(next_token_id.item())\n",
        "\n",
        "        if verbose:\n",
        "            print(\n",
        "                tokenizer.decode(next_token_id.tolist()),\n",
        "                end=\"\",\n",
        "                flush=True\n",
        "            )\n",
        "    return tokenizer.decode(generated_ids)\n",
        "\n",
        "\n",
        "skip_portion = False\n",
        "\n",
        "if not skip_portion:\n",
        "    generated_text = generate_text_stream_concat(\n",
        "        model, tokenizer, prompt, device,\n",
        "        max_new_tokens=2048,\n",
        "        verbose=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74f3939b-03f6-403f-9ee9-1ccd91f4fc19",
      "metadata": {
        "id": "74f3939b-03f6-403f-9ee9-1ccd91f4fc19"
      },
      "source": [
        "&nbsp;\n",
        "## 3.4 Extracting the final answer box"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5180c33c-a766-450b-a237-da1173174403",
      "metadata": {
        "id": "5180c33c-a766-450b-a237-da1173174403"
      },
      "source": [
        "- In this section, we extract the answer box (step 3); later, in the next section will take the extracted answer and normalize it (step 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f249918-b1e7-478a-ba90-876569805fba",
      "metadata": {
        "id": "0f249918-b1e7-478a-ba90-876569805fba"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/reasoning-from-scratch-images/ch03/CH03_F06_raschka.webp?1\" width=\"500px\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "188fec94-da7d-41ba-a101-62faed84ae48",
      "metadata": {
        "id": "188fec94-da7d-41ba-a101-62faed84ae48"
      },
      "outputs": [],
      "source": [
        "model_answer = (\n",
        "r\"\"\"... some explanation...\n",
        "**Final Answer:**\n",
        "\n",
        "\\[\n",
        "\\boxed{\\dfrac{14}{3}}\n",
        "\\]\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39a18b82-a592-49d2-8ae3-9db949fd3c1b",
      "metadata": {
        "id": "39a18b82-a592-49d2-8ae3-9db949fd3c1b"
      },
      "outputs": [],
      "source": [
        "def get_last_boxed(text):\n",
        "    # Find the last occurrence of \"\\boxed\"\n",
        "    boxed_start_idx = text.rfind(r\"\\boxed\")\n",
        "    if boxed_start_idx == -1:\n",
        "        return None\n",
        "\n",
        "    # Get position after \"\\boxed\"\n",
        "    current_idx = boxed_start_idx + len(r\"\\boxed\")\n",
        "\n",
        "    # Skip any whitespace after \"\\boxed\"\n",
        "    while current_idx < len(text) and text[current_idx].isspace():\n",
        "        current_idx += 1\n",
        "\n",
        "    # Expect an opening brace \"{\"\n",
        "    if current_idx >= len(text) or text[current_idx] != \"{\":\n",
        "        return None\n",
        "\n",
        "    # Parse the braces with nesting\n",
        "    current_idx += 1\n",
        "    brace_depth = 1\n",
        "    content_start_idx = current_idx\n",
        "\n",
        "    while current_idx < len(text) and brace_depth > 0:\n",
        "        char = text[current_idx]\n",
        "        if char == \"{\":\n",
        "            brace_depth += 1\n",
        "        elif char == \"}\":\n",
        "            brace_depth -= 1\n",
        "        current_idx += 1\n",
        "\n",
        "    # Account for unbalanced braces\n",
        "    if brace_depth != 0:\n",
        "        return None\n",
        "\n",
        "    # Extract content inside the outermost braces\n",
        "    return text[content_start_idx:current_idx-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c24fe48-80b5-4608-89f0-0e4afe7ab123",
      "metadata": {
        "id": "4c24fe48-80b5-4608-89f0-0e4afe7ab123"
      },
      "outputs": [],
      "source": [
        "extracted_answer = get_last_boxed(model_answer)\n",
        "print(extracted_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fe03f2f-ff52-4009-a241-bf3eef68e4fc",
      "metadata": {
        "id": "9fe03f2f-ff52-4009-a241-bf3eef68e4fc"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "RE_NUMBER = re.compile(\n",
        "    r\"-?(?:\\d+/\\d+|\\d+(?:\\.\\d+)?(?:[eE][+-]?\\d+)?)\"\n",
        ")\n",
        "\n",
        "def extract_final_candidate(text, fallback=\"number_then_full\"):\n",
        "    # Default return value if nothing matches\n",
        "    result = \"\"\n",
        "\n",
        "    if text:\n",
        "        # Prefer the last boxed expression if present\n",
        "        boxed = get_last_boxed(text.strip())\n",
        "        if boxed:\n",
        "            result = boxed.strip().strip(\"$ \")\n",
        "\n",
        "        # If no boxed expression, try fallback\n",
        "        elif fallback in (\"number_then_full\", \"number_only\"):\n",
        "            m = RE_NUMBER.findall(text)\n",
        "            if m:\n",
        "                # Use last number\n",
        "                result = m[-1]\n",
        "            elif fallback == \"number_then_full\":\n",
        "                # Else return full text if no number found\n",
        "                result = text\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "537225af-0184-48a5-a5a6-fc223c401231",
      "metadata": {
        "id": "537225af-0184-48a5-a5a6-fc223c401231"
      },
      "source": [
        "- fallback settings if no boxed content is found:\n",
        "    - \"number_then_full\": pick the last simple number, else the whole text\n",
        "    - \"number_only\": pick the last simple number, else return an empty string `\"\"`\n",
        "    - \"none\": extract only boxed content, else return empty string `\"\"`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ee81df6-dafb-4bdf-8608-04a871121f06",
      "metadata": {
        "id": "5ee81df6-dafb-4bdf-8608-04a871121f06"
      },
      "outputs": [],
      "source": [
        "print(extract_final_candidate(model_answer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64b63d7b-db95-465a-ba64-d476fce63ad9",
      "metadata": {
        "id": "64b63d7b-db95-465a-ba64-d476fce63ad9"
      },
      "outputs": [],
      "source": [
        "print(extract_final_candidate(r\"\\boxed{ 14/3. }\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07570c56-fb1f-45d6-a118-a4e71e116226",
      "metadata": {
        "id": "07570c56-fb1f-45d6-a118-a4e71e116226"
      },
      "outputs": [],
      "source": [
        "print(extract_final_candidate(\"abc < > 14/3 abc\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "570ebcc5-f682-4f70-a018-7529e1402575",
      "metadata": {
        "id": "570ebcc5-f682-4f70-a018-7529e1402575"
      },
      "outputs": [],
      "source": [
        "print(extract_final_candidate(\"Text without numbers\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45892c39-d78d-4ee2-9811-25fb8d4a04d7",
      "metadata": {
        "id": "45892c39-d78d-4ee2-9811-25fb8d4a04d7"
      },
      "source": [
        "&nbsp;\n",
        "## 3.5 Normalizing the extracted answer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f92fad0e-72fa-4bab-bbb4-e0010d26c8b7",
      "metadata": {
        "id": "f92fad0e-72fa-4bab-bbb4-e0010d26c8b7"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/reasoning-from-scratch-images/ch03/CH03_F07_raschka.webp?1\" width=\"500px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b870b559-3e14-44b7-91ce-ba01a6e08aab",
      "metadata": {
        "id": "b870b559-3e14-44b7-91ce-ba01a6e08aab"
      },
      "source": [
        "- In the previous section, we extracted the answer (step 3), now we are normalizing it (step 4 in the previous figure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a5a68e1-941a-4f3a-97f0-b83393aa923a",
      "metadata": {
        "id": "2a5a68e1-941a-4f3a-97f0-b83393aa923a"
      },
      "outputs": [],
      "source": [
        "LATEX_FIXES = [  # Latex formatting to be replaced\n",
        "    (r\"\\\\left\\s*\", \"\"),\n",
        "    (r\"\\\\right\\s*\", \"\"),\n",
        "    (r\"\\\\,|\\\\!|\\\\;|\\\\:\", \"\"),\n",
        "    (r\"\\\\cdot\", \"*\"),\n",
        "    (r\"\\u00B7|\\u00D7\", \"*\"),\n",
        "    (r\"\\\\\\^\\\\circ\", \"\"),\n",
        "    (r\"\\\\dfrac\", r\"\\\\frac\"),\n",
        "    (r\"\\\\tfrac\", r\"\\\\frac\"),\n",
        "    (r\"°\", \"\"),\n",
        "]\n",
        "\n",
        "RE_SPECIAL = re.compile(r\"<\\|[^>]+?\\|>\")  # strip chat special tokens like <|assistant|>\n",
        "\n",
        "def normalize_text(text):\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    text = RE_SPECIAL.sub(\"\", text).strip()\n",
        "\n",
        "    # Remove angle-degree markers\n",
        "    text = re.sub(r\"\\^\\s*\\{\\s*\\\\circ\\s*\\}\", \"\", text)   # ^{\\circ}\n",
        "    text = re.sub(r\"\\^\\s*\\\\circ\", \"\", text)             # ^\\circ\n",
        "    text = text.replace(\"°\", \"\")                        # Unicode degree\n",
        "\n",
        "    # unwrap \\text{...} if the whole string is wrapped\n",
        "    match = re.match(r\"^\\\\text\\{(?P<x>.+?)\\}$\", text)\n",
        "    if match:\n",
        "        text = match.group(\"x\")\n",
        "\n",
        "    # strip inline/display math wrappers \\( \\) \\[ \\]\n",
        "    text = re.sub(r\"\\\\\\(|\\\\\\)|\\\\\\[|\\\\\\]\", \"\", text)\n",
        "\n",
        "    # light LaTeX canonicalization\n",
        "    for pat, rep in LATEX_FIXES:\n",
        "        text = re.sub(pat, rep, text)\n",
        "\n",
        "    # numbers/roots\n",
        "    text = text.replace(\"\\\\%\", \"%\").replace(\"$\", \"\").replace(\"%\", \"\")\n",
        "    text = re.sub(\n",
        "        r\"\\\\sqrt\\s*\\{([^}]*)\\}\",\n",
        "        lambda match: f\"sqrt({match.group(1)})\",\n",
        "        text,\n",
        "    )\n",
        "    text = re.sub(\n",
        "        r\"\\\\sqrt\\s+([^\\\\\\s{}]+)\",\n",
        "        lambda match: f\"sqrt({match.group(1)})\",\n",
        "        text,\n",
        "    )\n",
        "\n",
        "    # fractions\n",
        "    text = re.sub(\n",
        "        r\"\\\\frac\\s*\\{([^{}]+)\\}\\s*\\{([^{}]+)\\}\",\n",
        "        lambda match: f\"({match.group(1)})/({match.group(2)})\",\n",
        "        text,\n",
        "    )\n",
        "    text = re.sub(\n",
        "        r\"\\\\frac\\s+([^\\s{}]+)\\s+([^\\s{}]+)\",\n",
        "        lambda match: f\"({match.group(1)})/({match.group(2)})\",\n",
        "        text,\n",
        "    )\n",
        "\n",
        "    # exponent and mixed numbers\n",
        "    text = text.replace(\"^\", \"**\")\n",
        "    text = re.sub(\n",
        "        r\"(?<=\\d)\\s+(\\d+/\\d+)\",\n",
        "        lambda match: \"+\" + match.group(1),\n",
        "        text,\n",
        "    )\n",
        "\n",
        "    # 1,234 -> 1234\n",
        "    text = re.sub(\n",
        "        r\"(?<=\\d),(?=\\d\\d\\d(\\D|$))\",\n",
        "        \"\",\n",
        "        text,\n",
        "    )\n",
        "\n",
        "    return text.replace(\"{\", \"\").replace(\"}\", \"\").strip().lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1668039-be17-46e0-8477-40307b8235fc",
      "metadata": {
        "id": "b1668039-be17-46e0-8477-40307b8235fc"
      },
      "outputs": [],
      "source": [
        "print(normalize_text(extract_final_candidate(model_answer)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7610b999-3460-4b5b-896b-a24f1582c48d",
      "metadata": {
        "id": "7610b999-3460-4b5b-896b-a24f1582c48d"
      },
      "outputs": [],
      "source": [
        "print(normalize_text(r\"$\\dfrac{14}{3.}$\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f37027f8-8f56-4c8e-90d8-a87f1720732a",
      "metadata": {
        "id": "f37027f8-8f56-4c8e-90d8-a87f1720732a"
      },
      "outputs": [],
      "source": [
        "print(normalize_text(r\"\\text{\\[\\frac{14}{3}\\]}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bd95965-1e2c-4926-affb-dff0ed4d35ca",
      "metadata": {
        "id": "5bd95965-1e2c-4926-affb-dff0ed4d35ca"
      },
      "outputs": [],
      "source": [
        "print(normalize_text(\"4/3\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "027df598-a37b-4951-8d3f-51e4e0435929",
      "metadata": {
        "id": "027df598-a37b-4951-8d3f-51e4e0435929"
      },
      "source": [
        "&nbsp;\n",
        "## 3.6 Verifying mathematical equivalence"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9a0e3e2-54f8-4878-8f1e-2f891775ae69",
      "metadata": {
        "id": "a9a0e3e2-54f8-4878-8f1e-2f891775ae69"
      },
      "source": [
        "- In this section, we implement the basic functionality to check if the extracted answer (generated by the model) is equivalent to the correct answer (ground truth) provided in the dataset; this is step 5\n",
        "- In the next section (step 6), we make this process a bit more robust to grade the answer correctness"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97eb9445-9eb8-464e-9116-eebe86a8a189",
      "metadata": {
        "id": "97eb9445-9eb8-464e-9116-eebe86a8a189"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/reasoning-from-scratch-images/ch03/CH03_F08_raschka.webp?1\" width=\"500px\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f80dc58-c3f4-4d1c-b22a-8059b0b2d264",
      "metadata": {
        "id": "6f80dc58-c3f4-4d1c-b22a-8059b0b2d264"
      },
      "outputs": [],
      "source": [
        "from sympy.parsing import sympy_parser as spp\n",
        "from sympy.core.sympify import SympifyError\n",
        "\n",
        "def sympy_parser(expr):\n",
        "    try:\n",
        "        return spp.parse_expr(\n",
        "            expr,\n",
        "            transformations=(\n",
        "                # Standard transformations like handling parentheses\n",
        "                *spp.standard_transformations,\n",
        "\n",
        "                # Allow omitted multiplication symbols (e.g., \"2x\" -> 2*x\")\n",
        "                spp.implicit_multiplication_application,\n",
        "            ),\n",
        "\n",
        "            # Evaluate during parsing so simple constants simplify (e.g., 2+3 -> 5)\n",
        "            evaluate=True,\n",
        "        )\n",
        "    except (SympifyError, SyntaxError, TypeError, IndexError):\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c7b29a0-b446-490e-a8f2-6fcafe598abd",
      "metadata": {
        "id": "7c7b29a0-b446-490e-a8f2-6fcafe598abd"
      },
      "source": [
        "- Note that this appears to be an excessive amount of error handling, but these are all errors that I encountered when evaluating the model on all 500 MATH-500 problems as the model does not always generate perfectly formatted outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f9b25c6-1038-4d37-be3f-a6bb7c543f7b",
      "metadata": {
        "id": "7f9b25c6-1038-4d37-be3f-a6bb7c543f7b"
      },
      "outputs": [],
      "source": [
        "print(sympy_parser(normalize_text(\n",
        "    extract_final_candidate(model_answer)\n",
        ")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "072e1d5f-c785-46ce-ad17-524c2f7a7ef4",
      "metadata": {
        "id": "072e1d5f-c785-46ce-ad17-524c2f7a7ef4"
      },
      "outputs": [],
      "source": [
        "print(sympy_parser(\"28/6\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c291308-571b-4bce-849d-27f297f6cc75",
      "metadata": {
        "id": "8c291308-571b-4bce-849d-27f297f6cc75"
      },
      "outputs": [],
      "source": [
        "from sympy import simplify\n",
        "\n",
        "def equality_check(expr_gtruth, expr_pred):\n",
        "    # First, check if the two expressions are exactly the same string\n",
        "    if expr_gtruth == expr_pred:\n",
        "        return True\n",
        "\n",
        "    # Parse both expressions into SymPy objects (returns None if parsing fails)\n",
        "    gtruth, pred = sympy_parser(expr_gtruth), sympy_parser(expr_pred)\n",
        "\n",
        "    # If both expressions were parsed successfully, try symbolic comparison\n",
        "    if gtruth is not None and pred is not None:\n",
        "        try:\n",
        "            # If the difference is 0, they are equivalent\n",
        "            return simplify(gtruth - pred) == 0\n",
        "        except (SympifyError, TypeError):\n",
        "            pass\n",
        "\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88bd9c22-44b1-4885-9bda-997f6b91ccfd",
      "metadata": {
        "id": "88bd9c22-44b1-4885-9bda-997f6b91ccfd"
      },
      "outputs": [],
      "source": [
        "print(equality_check(\n",
        "    normalize_text(\"13/4.\"),\n",
        "    normalize_text(r\"(13)/(4)\")\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccf2e7ec-2d24-44db-8f4f-c530f460f1b5",
      "metadata": {
        "id": "ccf2e7ec-2d24-44db-8f4f-c530f460f1b5"
      },
      "outputs": [],
      "source": [
        "print(equality_check(\n",
        "    normalize_text(\"0.5\"),\n",
        "    normalize_text(r\"(1)/(2)\")\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c19d5b7f-5653-41c4-a4c3-9661ced08b12",
      "metadata": {
        "id": "c19d5b7f-5653-41c4-a4c3-9661ced08b12"
      },
      "outputs": [],
      "source": [
        "print(equality_check(\n",
        "    normalize_text(\"14/3\"),\n",
        "    normalize_text(\"15/3\")\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad64d868-32de-49d6-b078-7436d54e3252",
      "metadata": {
        "id": "ad64d868-32de-49d6-b078-7436d54e3252"
      },
      "outputs": [],
      "source": [
        "print(equality_check(\n",
        "    normalize_text(\"(14/3, 2/3)\"),\n",
        "    normalize_text(\"(14/3, 4/6)\")\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe7581df-4461-483b-b612-57c9bdc52032",
      "metadata": {
        "id": "fe7581df-4461-483b-b612-57c9bdc52032"
      },
      "source": [
        "&nbsp;\n",
        "## 3.7 Grading answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24b6d454-feb7-4786-85b1-b55f33df840c",
      "metadata": {
        "id": "24b6d454-feb7-4786-85b1-b55f33df840c"
      },
      "outputs": [],
      "source": [
        "def split_into_parts(text):\n",
        "    result = [text]\n",
        "\n",
        "    if text:\n",
        "        # Check if text looks like a tuple or list, e.g. \"(a, b)\" or \"[a, b]\"\n",
        "        if (\n",
        "            len(text) >= 2\n",
        "            and text[0] in \"([\" and text[-1] in \")]\"\n",
        "            and \",\" in text[1:-1]\n",
        "        ):\n",
        "            # Split on commas inside brackets and strip whitespace\n",
        "            items = [p.strip() for p in text[1:-1].split(\",\")]\n",
        "            if all(items):\n",
        "                result = items\n",
        "    else:\n",
        "        # If text is empty, return an empty list\n",
        "        result = []\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07e3f1f8-6e8c-4440-bda8-96480ca0d5c6",
      "metadata": {
        "id": "07e3f1f8-6e8c-4440-bda8-96480ca0d5c6"
      },
      "outputs": [],
      "source": [
        "split_into_parts(normalize_text(r\"(14/3, 2/3)\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf17996c-3bd3-496a-a47b-b426b51ab208",
      "metadata": {
        "id": "bf17996c-3bd3-496a-a47b-b426b51ab208"
      },
      "outputs": [],
      "source": [
        "def grade_answer(pred_text, gt_text):\n",
        "    result = False  # Default outcome if checks fail\n",
        "\n",
        "    # Only continue if both inputs are non-empty strings\n",
        "    if pred_text is not None and gt_text is not None:\n",
        "        gt_parts = split_into_parts(\n",
        "            normalize_text(gt_text)\n",
        "        )  # Break ground truth into comparable parts\n",
        "\n",
        "        pred_parts = split_into_parts(\n",
        "            normalize_text(pred_text)\n",
        "        )  # Break prediction into comparable parts\n",
        "\n",
        "        # Ensure both sides have same number of valid parts\n",
        "        if (gt_parts and pred_parts\n",
        "           and len(gt_parts) == len(pred_parts)):\n",
        "            result = all(\n",
        "                equality_check(gt, pred)\n",
        "                for gt, pred in zip(gt_parts, pred_parts)\n",
        "            )  # Check each part for mathematical equivalence\n",
        "\n",
        "    return result  # True only if all checks passed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6da8ea2e-060a-4055-90db-c7f050677f53",
      "metadata": {
        "id": "6da8ea2e-060a-4055-90db-c7f050677f53"
      },
      "outputs": [],
      "source": [
        "grade_answer(\"14/3\", r\"\\frac{14}{3}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f577aadf-7c42-49ff-a200-032b2f3f0aba",
      "metadata": {
        "id": "f577aadf-7c42-49ff-a200-032b2f3f0aba"
      },
      "outputs": [],
      "source": [
        "grade_answer(r\"(14/3, 2/3)\", \"(14/3, 4/6)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7484d6ea-b5a1-4a3b-b9f1-dcda0dec8f38",
      "metadata": {
        "id": "7484d6ea-b5a1-4a3b-b9f1-dcda0dec8f38"
      },
      "outputs": [],
      "source": [
        "# Define test cases: (name, prediction, ground truth, expected result)\n",
        "tests = [\n",
        "        (\"check_1\", \"3/4\", r\"\\frac{3}{4}\", True),\n",
        "        (\"check_2\", \"(3)/(4)\", r\"3/4\", True),\n",
        "        (\"check_3\", r\"\\frac{\\sqrt{8}}{2}\", \"sqrt(2)\", True),\n",
        "        (\"check_4\", r\"\\( \\frac{1}{2} + \\frac{1}{6} \\)\", \"2/3\", True),\n",
        "        (\"check_5\", \"(1, 2)\", r\"(1,2)\", True),\n",
        "        (\"check_6\", \"(2, 1)\", \"(1, 2)\", False),\n",
        "        (\"check_7\", \"(1, 2, 3)\", \"(1, 2)\", False),\n",
        "        (\"check_8\", \"0.5\", \"1/2\", True),\n",
        "        (\"check_9\", \"0.3333333333\", \"1/3\", False),\n",
        "        (\"check_10\", \"1,234/2\", \"617\", True),\n",
        "        (\"check_11\", r\"\\text{2/3}\", \"2/3\", True),\n",
        "        (\"check_12\", \"50%\", \"1/2\", False),\n",
        "        (\"check_13\", r\"2\\cdot 3/4\", \"3/2\", True),\n",
        "        (\"check_14\", r\"90^\\circ\", \"90\", True),\n",
        "        (\"check_15\", r\"\\left(\\frac{3}{4}\\right)\", \"3/4\", True),\n",
        "    ]\n",
        "\n",
        "\n",
        "def run_demos_table(tests):\n",
        "    header = (\"Test\", \"Expect\", \"Got\", \"Status\")\n",
        "    rows = []\n",
        "    for name, pred, gtruth, expect in tests:\n",
        "        got = grade_answer(pred, gtruth)  # Run equality check\n",
        "        status = \"PASS\" if got == expect else \"FAIL\"\n",
        "        rows.append((name, str(expect), str(got), status))\n",
        "\n",
        "    data = [header] + rows\n",
        "\n",
        "    # Compute max width for each column to align table nicely\n",
        "    col_widths = [\n",
        "        max(len(row[i]) for row in data)\n",
        "        for i in range(len(header))\n",
        "    ]\n",
        "\n",
        "    # Print table row by row\n",
        "    for row in data:\n",
        "        line = \" | \".join(\n",
        "            row[i].ljust(col_widths[i])\n",
        "            for i in range(len(header))\n",
        "        )\n",
        "        print(line)\n",
        "\n",
        "    # Print summary of passed tests\n",
        "    passed = sum(r[3] == \"PASS\" for r in rows)\n",
        "    print(f\"\\nPassed {passed}/{len(rows)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dc20c84-44eb-443d-9fd1-852f347fa7ff",
      "metadata": {
        "id": "7dc20c84-44eb-443d-9fd1-852f347fa7ff"
      },
      "outputs": [],
      "source": [
        "run_demos_table(tests)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34224da7-26c5-4523-96e4-10eeb0623a64",
      "metadata": {
        "id": "34224da7-26c5-4523-96e4-10eeb0623a64"
      },
      "source": [
        "&nbsp;\n",
        "## 3.8 Loading the evaluation dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b109d67c-5af4-4c01-a6c0-64444854a911",
      "metadata": {
        "id": "b109d67c-5af4-4c01-a6c0-64444854a911"
      },
      "source": [
        "- The previous section implemented the basic evaluation pipeline\n",
        "- In this section, we load the dataset (step 7) to which we will apply this pipeline in order to evaluate the model (step 8, next section)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2c21118-483d-4674-811c-b0ede83dd5b9",
      "metadata": {
        "id": "c2c21118-483d-4674-811c-b0ede83dd5b9"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/reasoning-from-scratch-images/ch03/CH03_F09_raschka.webp?1\" width=\"500px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d2dfa44-bc95-4629-8773-63fe40581e80",
      "metadata": {
        "id": "0d2dfa44-bc95-4629-8773-63fe40581e80"
      },
      "source": [
        "- The dataset was downloaded and prepared via the following code from the [HuggingFaceH4/MATH-500](https://huggingface.co/datasets/HuggingFaceH4/MATH-500) repository, which requires the [`datasets`](https://huggingface.co/docs/datasets/en/index) package depencency (you don't need to execute this, it's only included for reference):\n",
        "\n",
        "```python\n",
        "from datasets import load_dataset\n",
        "import json\n",
        "\n",
        "dset = load_dataset(\"HuggingFaceH4/MATH-500\", split=\"test\")\n",
        "\n",
        "math_data = dset.to_list()\n",
        "with open(\"math500_test.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(math_data, f, ensure_ascii=False, indent=2)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3381aa3-7980-49aa-a0db-11fe0ef837f1",
      "metadata": {
        "id": "b3381aa3-7980-49aa-a0db-11fe0ef837f1"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import requests\n",
        "\n",
        "local_path = Path(\"math500_test.json\")\n",
        "url = (\n",
        "    \"https://raw.githubusercontent.com/rasbt/reasoning-from-scratch/\"\n",
        "    \"main/ch03/01_main-chapter-code/math500_test.json\"\n",
        ")\n",
        "\n",
        "if local_path.exists():\n",
        "    with local_path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        math_data = json.load(f)\n",
        "else:\n",
        "    r = requests.get(url, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    math_data = r.json()\n",
        "\n",
        "print(\"Number of entries:\", len(math_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17fd27ff-792c-4450-9680-b673db46210e",
      "metadata": {
        "id": "17fd27ff-792c-4450-9680-b673db46210e"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "pprint(math_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6229ba79-216f-4d04-9654-e1df2796b9f9",
      "metadata": {
        "id": "6229ba79-216f-4d04-9654-e1df2796b9f9"
      },
      "source": [
        "&nbsp;\n",
        "## 3.9 Evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41dc5c3c-3287-4ff4-b8df-719b59355a45",
      "metadata": {
        "id": "41dc5c3c-3287-4ff4-b8df-719b59355a45"
      },
      "source": [
        "- In the previous section, we loaded the dataset; now we can apply the evaluation pipeline to evaluate the model on this dataset (step 7)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cdd1b75-9234-4241-bcd5-2238908ca1f0",
      "metadata": {
        "id": "5cdd1b75-9234-4241-bcd5-2238908ca1f0"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/reasoning-from-scratch-images/ch03/CH03_F10_raschka.webp?1\" width=\"500px\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a017826b-6a5d-4586-8fb3-5c8fbf754eef",
      "metadata": {
        "id": "a017826b-6a5d-4586-8fb3-5c8fbf754eef"
      },
      "outputs": [],
      "source": [
        "def render_prompt(prompt):\n",
        "    template = (\n",
        "        \"You are a helpful math assistant.\\n\"\n",
        "        \"Answer the question and write the final result on a new line as:\\n\"\n",
        "        \"\\\\boxed{ANSWER}\\n\\n\"\n",
        "        f\"Question:\\n{prompt}\\n\\nAnswer:\"\n",
        "    )\n",
        "    return template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9386b940-e6da-4c47-8bea-9bc40c31eebc",
      "metadata": {
        "id": "9386b940-e6da-4c47-8bea-9bc40c31eebc"
      },
      "outputs": [],
      "source": [
        "prompt = (  # Same prompt we used at the beginning of the chapter\n",
        "    r\"If $a+b=3$ and $ab=\\tfrac{13}{6}$, \"\n",
        "    r\"what is the value of $a^2+b^2$?\"\n",
        ")\n",
        "prompt_fmt = render_prompt(prompt)\n",
        "print(prompt_fmt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70d1cf2e-5a34-45b2-88dd-761c4fc11300",
      "metadata": {
        "id": "70d1cf2e-5a34-45b2-88dd-761c4fc11300"
      },
      "outputs": [],
      "source": [
        "generated_text = generate_text_stream_concat(\n",
        "    model, tokenizer, prompt_fmt, device,\n",
        "    max_new_tokens=2048,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34d82a23-cd19-4983-8593-795e569af49f",
      "metadata": {
        "id": "34d82a23-cd19-4983-8593-795e569af49f"
      },
      "outputs": [],
      "source": [
        "# Below is an alternative prompt template\n",
        "# which swaps \"Question\" with \"Problem\"\n",
        "\n",
        "\"\"\"\n",
        "def render_prompt(prompt):\n",
        "    template = (\n",
        "        \"You are a helpful math assistant.\\n\"\n",
        "        \"Solve the problem and write the final result on a new line as:\\n\"\n",
        "        \"\\\\boxed{ANSWER}\\n\\n\"\n",
        "        f\"Problem:\\n{prompt}\\n\\nAnswer:\"\n",
        "    )\n",
        "    return template\n",
        "\"\"\"\n",
        "\n",
        "# This can noticeably affect the MATH-500 results:\n",
        "# Base model on mps: improves accuracy 20% -> 40%\n",
        "# Reasoning model on mps: worsens accuracy 90% -> 60%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff06715b-dff4-48fe-9880-aca24e19ec14",
      "metadata": {
        "id": "ff06715b-dff4-48fe-9880-aca24e19ec14"
      },
      "outputs": [],
      "source": [
        "# Alternatively, we may use no prompt template\n",
        "\n",
        "\"\"\"\n",
        "def render_prompt(prompt):\n",
        "    return prompt\n",
        "\"\"\"\n",
        "\n",
        "# This can noticeably affect the MATH-500 results:\n",
        "# Base model on mps: improves accuracy 20% -> 70%\n",
        "# Reasoning model on mps: worsens accuracy 90% -> 50%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e84752c-a379-4c2e-b4e0-05ae2b98364f",
      "metadata": {
        "id": "9e84752c-a379-4c2e-b4e0-05ae2b98364f"
      },
      "outputs": [],
      "source": [
        "def mini_eval_demo(model, tokenizer, device):\n",
        "    ex = {  # Test example with \"problem\" and \"answer\" fields\n",
        "        \"problem\": \"Compute 1/2 + 1/6.\",\n",
        "        \"answer\": \"2/3\"\n",
        "    }\n",
        "    prompt = render_prompt(ex[\"problem\"])     # 1. Apply prompt template\n",
        "    gen_text = generate_text_stream_concat(   # 2. Generate response\n",
        "        model, tokenizer, prompt, device,\n",
        "        max_new_tokens=64,\n",
        "    )\n",
        "    pred_answer = extract_final_candidate(gen_text)  # 3. Extract and normalize answer\n",
        "    is_correct = grade_answer(                       # 4. Grade answer\n",
        "        pred_answer, ex[\"answer\"]\n",
        "    )\n",
        "    print(f\"Device: {device}\")\n",
        "    print(f\"Prediction: {pred_answer}\")\n",
        "    print(f\"Ground truth: {ex['answer']}\")\n",
        "    print(f\"Correct: {is_correct}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d45fa99-1502-4484-bfd6-6421ba76b3cb",
      "metadata": {
        "id": "9d45fa99-1502-4484-bfd6-6421ba76b3cb"
      },
      "outputs": [],
      "source": [
        "mini_eval_demo(model, tokenizer, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0f91082-e578-4c82-a55d-a0bfcb82e151",
      "metadata": {
        "id": "d0f91082-e578-4c82-a55d-a0bfcb82e151"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "\n",
        "def evaluate_math500_stream(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    device,\n",
        "    math_data,\n",
        "    out_path=None,\n",
        "    max_new_tokens=512,\n",
        "    verbose=False,\n",
        "):\n",
        "\n",
        "    if out_path is None:\n",
        "        dev_name = str(device).replace(\":\", \"-\")  # Make filename compatible with Windows\n",
        "        out_path = Path(f\"math500_{WHICH_MODEL}-{dev_name}.jsonl\")\n",
        "\n",
        "    num_examples = len(math_data)\n",
        "    num_correct = 0\n",
        "    print(f\"MATH-500: 0/{num_examples}\", end=\"\\r\", flush=True)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:  # Save results for inspection\n",
        "        for i, row in enumerate(math_data, start=1):\n",
        "            prompt = render_prompt(row[\"problem\"])    # 1. Apply prompt template\n",
        "            gen_text = generate_text_stream_concat(   # 2. Generate response\n",
        "                model, tokenizer, prompt, device,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                verbose=verbose,\n",
        "            )\n",
        "\n",
        "            extracted = extract_final_candidate(  # 3. Extract and normalize answer\n",
        "                gen_text\n",
        "            )\n",
        "            is_correct = grade_answer(            # 4. Grade answer\n",
        "                extracted, row[\"answer\"]\n",
        "            )\n",
        "            num_correct += int(is_correct)\n",
        "\n",
        "            record = {  # Record to be saved for inspection\n",
        "                \"index\": i,\n",
        "                \"problem\": row[\"problem\"],\n",
        "                \"gtruth_answer\": row[\"answer\"],\n",
        "                \"generated_text\": gen_text,\n",
        "                \"extracted\": extracted,\n",
        "                \"correct\": bool(is_correct),\n",
        "            }\n",
        "            f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "            if verbose:  # Print responses during the generation process\n",
        "                print(\n",
        "                    f\"\\n\\n{'='*50}\\nMATH-500: {i}/{num_examples}\\n\"\n",
        "                    f\"{'='*50}\\nExtracted: {extracted}\\n\"\n",
        "                    f\"Expected:  {row['answer']}\\n\"\n",
        "                    f\"Correct so far: {num_correct}\\n{'-'*50}\"\n",
        "                )\n",
        "            else:\n",
        "                print(\n",
        "                    f\"MATH-500: {i}/{num_examples}\",\n",
        "                    end=\"\\r\", flush=True\n",
        "                )\n",
        "\n",
        "    # Print summary information\n",
        "    seconds_elapsed = time.time() - start_time\n",
        "    acc = num_correct / num_examples if num_examples else 0.0\n",
        "    print(f\"\\nAccuracy: {acc*100:.1f}% ({num_correct}/{num_examples})\")\n",
        "    print(f\"Total time: {seconds_elapsed/60:.1f} min\")\n",
        "    print(f\"Logs written to: {out_path}\")\n",
        "    return num_correct, num_examples, acc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5fa386b-de7d-46e1-b25a-5fec740421e8",
      "metadata": {
        "id": "f5fa386b-de7d-46e1-b25a-5fec740421e8"
      },
      "source": [
        "- We only evaluate on 10 examples for demo purposes (to keep the runtime reasonable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42befbdf-feb9-453c-acb5-910c7c981ea3",
      "metadata": {
        "id": "42befbdf-feb9-453c-acb5-910c7c981ea3"
      },
      "outputs": [],
      "source": [
        "print(\"Model:\", WHICH_MODEL)\n",
        "print(\"Device:\", device)\n",
        "num_correct, num_examples, acc = evaluate_math500_stream(\n",
        "    model, tokenizer, device,\n",
        "    math_data=math_data[:10],\n",
        "    max_new_tokens=2048,\n",
        "    verbose=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8543773b-2d8d-4917-b0cb-25ec0da7e2b9",
      "metadata": {
        "id": "8543773b-2d8d-4917-b0cb-25ec0da7e2b9"
      },
      "source": [
        "| Mode      | Device | Accuracy | MATH-500 size\n",
        "|-----------|--------|----------| ------------\n",
        "| Base      | CPU    | 30%      | 10\n",
        "| Base      | CUDA   | 30%      | 10\n",
        "| Base      | MPS    | 20%      | 10\n",
        "| Reasoning | CPU    | 90%      | 10\n",
        "| Reasoning | CUDA   | 90%      | 10\n",
        "| Reasoning | MPS    | 80%      | 10\n",
        "|           |        |          |\n",
        "| Base      | CUDA   | 15.3%    | 500\n",
        "| Reasoning | CUDA   | 50.8%    | 500"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d69cd3e-202b-4537-bd80-312b160ec904",
      "metadata": {
        "id": "9d69cd3e-202b-4537-bd80-312b160ec904"
      },
      "source": [
        "- For reference, above are the different accuracy values\n",
        "- Note that \"GPU\" here refers to a NVIDIA (\"cuda\") GPU; MPS refers to an Apple Silicon M4 chip\n",
        "- It takes about 0.7 min to evaluate the base model (on a M4 Mac Mini) and about 7 min to evaluate the reasoning model, since it produces much longer responses\n",
        "- While Qwen3-Base is a pre-trained base model and the Qwen3 recommends using it without chat template, changing `tokenizer = Qwen3Tokenizer(tokenizer_file_path=tokenizer_path)` to `tokenizer = Qwen3Tokenizer(tokenizer_file_path=tokenizer_path, apply_chat_template=True)` boosts the MATH-500 performance substantially (80%); note that it is not clear whether the MATH-500 test set was part of the training data; in the age of LLMs, we can assume that any data available on the internet has been part of the training data (also see the discussion [here](https://github.com/rasbt/LLMs-from-scratch/pull/828#issuecomment-3324829736))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98a2fb3d-0c5a-4edf-8a2a-9227e3acc34c",
      "metadata": {
        "id": "98a2fb3d-0c5a-4edf-8a2a-9227e3acc34c"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/reasoning-from-scratch-images/ch03/CH03_F11_raschka.webp?1\" width=\"500px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32ae09ba-9989-4a76-a3c3-72ca792c2637",
      "metadata": {
        "id": "32ae09ba-9989-4a76-a3c3-72ca792c2637"
      },
      "source": [
        "- For convenience, you can use the [../02_math500-verifier-scripts/evaluate_math500.py](../02_math500-verifier-scripts/evaluate_math500.py) script, which runs the MATH-500 evaluation code as a standalone script from the command line (see the [../02_math500-verifier-scripts/README.md](../02_math500-verifier-scripts/README.md) for more usage information)\n",
        "- The [../02_math500-verifier-scripts/evaluate_math500_batched.py](../02_math500-verifier-scripts/evaluate_math500_batched.py) script runs the code in this chapter in batched mode\n",
        "  - This means it processes multiple examples per forward pass to accelerate the evaluation while requiring more RAM\n",
        "  - With a batch size of 128, this reduces the runtime of the base model, when evaluating all 500 samples, from 13.3 min to 3.3 min on an H100 GPU\n",
        "  - Similarly, it reduces the runtime of the reasoning model from 185.4 min to 14.6 min for the 500 examples in the dataset\n",
        "  - Note that the H100 is used as an example, and the script is compatible with other GPUs (or CPUs) as well"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdc25545-9cac-40a8-b08f-fd42701e332a",
      "metadata": {
        "id": "fdc25545-9cac-40a8-b08f-fd42701e332a"
      },
      "source": [
        "&nbsp;\n",
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b66ffc8-3f44-4784-9cd3-4772dee6333d",
      "metadata": {
        "id": "7b66ffc8-3f44-4784-9cd3-4772dee6333d"
      },
      "source": [
        "- No code in this section"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}