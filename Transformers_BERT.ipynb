{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7V8W9fRrXjOOJzuigsjN2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aleszcz/Aleks_portfolio/blob/main/Transformers_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BERT and transformers"
      ],
      "metadata": {
        "id": "UNA324_aC5DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJ1Y4GGQAb3r"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(precision=5, suppress=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_Words = 3\n",
        "embedding_dim = 4\n",
        "Xword2vec = np.array ([[1.769, 2.22, 3.4, 5.8],[7.3, 9.9, 8.5, 7.1],[9.1, 7.1, 0.85, 10.1]])\n",
        "print (Xword2vec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNLlo71IApQk",
        "outputId": "bd8a275b-394a-4297-8fe7-b5110f6e17c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.769  2.22   3.4    5.8  ]\n",
            " [ 7.3    9.9    8.5    7.1  ]\n",
            " [ 9.1    7.1    0.85  10.1  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#computing possitional encoding\n",
        "pos_encoding = np.zeros((num_Words,embedding_dim))\n",
        "\n",
        "for i in range(num_Words):\n",
        "  for j in  range(0, embedding_dim,2):\n",
        "    pos_encoding[i,j] = np.sin(i/10000**(2*j/embedding_dim))\n",
        "    pos_encoding[i, j+1] = np.cos(i/(10000**(2*j/embedding_dim)))\n",
        "print(pos_encoding)\n",
        "print(pos_encoding.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18RZIj2MBEMP",
        "outputId": "23040692-1beb-4c2f-fb86-6c1209b35157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.       1.       0.       1.     ]\n",
            " [ 0.84147  0.5403   0.0001   1.     ]\n",
            " [ 0.9093  -0.41615  0.0002   1.     ]]\n",
            "(3, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BERTword2vec = Xword2vec + pos_encoding\n",
        "print(BERTword2vec)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq_0SBH7B7pG",
        "outputId": "60323370-1f32-46b0-8ef8-1f2bcd6299a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.769    3.22     3.4      6.8    ]\n",
            " [ 8.14147 10.4403   8.51     8.09995]\n",
            " [10.0093   6.68385  0.87    11.0998 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.set_printoptions(precision=5, suppress=True)\n",
        "num_words = 3\n",
        "embedding_dim = 4\n",
        "Xword2vec = np.array([[1.769, 2.22, 3.4, 5.8], [7.3, 9.9, 8.5, 7.1], [9.1, 7.1, 0.85, 10.1]])\n",
        "print(Xword2vec)  # computing positional encoding\n",
        "pos_encoding = np.zeros((num_words, embedding_dim))\n",
        "\n",
        "for i in range(num_words):\n",
        "    for j in range(embedding_dim // 2):\n",
        "        pos_encoding[i, 2*j] = np.sin(i / (10000 ** (2*j / embedding_dim)))\n",
        "        pos_encoding[i, 2*j+1] = np.cos(i / (10000 ** (2*j / embedding_dim)))\n",
        "print(pos_encoding)\n",
        "print(pos_encoding.shape)\n",
        "BERTword2vec = Xword2vec + pos_encoding\n",
        "print(BERTword2vec)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiAmeUQ7Cpuu",
        "outputId": "f57ab500-c449-4541-e1ff-0f6c2211ab14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.769  2.22   3.4    5.8  ]\n",
            " [ 7.3    9.9    8.5    7.1  ]\n",
            " [ 9.1    7.1    0.85  10.1  ]]\n",
            "[[ 0.       1.       0.       1.     ]\n",
            " [ 0.84147  0.5403   0.01     0.99995]\n",
            " [ 0.9093  -0.41615  0.02     0.9998 ]]\n",
            "(3, 4)\n",
            "[[ 1.769    3.22     3.4      6.8    ]\n",
            " [ 8.14147 10.4403   8.51     8.09995]\n",
            " [10.0093   6.68385  0.87    11.0998 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TRANSFORMES hugging face and all the models in one place plus source of the python code of\n",
        "#the models and applictions\n"
      ],
      "metadata": {
        "id": "bXWKAUmvDWgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LXvE4VTzDWit"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}